{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.15 |Anaconda, Inc.| (default, Nov 13 2018, 17:07:45) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli\n",
    "from matplotlib import cm\n",
    "from numpy import linalg as LA\n",
    "from mpl_toolkits.mplot3d import Axes3D # This import has side effects required for the kwarg projection='3d' in the call to fig.add_subplot\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import generative_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generative_lib' from 'generative_lib.pyc'>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(generative_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers import AdversarialExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(adversary_path, delta = 500.0):\n",
    "    af = open(adversary_path, \"rb\")\n",
    "    exs = pickle.load(af)\n",
    "    af.close()\n",
    "\n",
    "    # remove all adversary that is None\n",
    "    exs = filter(lambda ex: ex is not None, exs)\n",
    "    # remove all adversary whose norm is > delta\n",
    "    exs = filter(lambda ex: ex.adv_diff_norm < delta, exs)\n",
    "    # sort examples by increasing diff norm\n",
    "    exs.sort(key = lambda ex: ex.adv_diff_norm)\n",
    "    \n",
    "    return exs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_lat(exs,AE,AEgen):\n",
    "    \n",
    "    # reconstruction by projection\n",
    "    maxit = 500\n",
    "    gamma  = 0.5\n",
    "    x0    = torch.zeros([num_hidden_1])\n",
    "    rand_init = 1\n",
    "    sigma = 5\n",
    "    \n",
    "    AE_latent_L2  = [];\n",
    "    AE_latent     = [];\n",
    "    \n",
    "    for ex in exs:\n",
    "        Gstar = ex.adv_x.reshape(image_width*image_width)\n",
    "\n",
    "        # latent via encoder\n",
    "        latEnc = AE.encoder(Gstar)\n",
    "        AE_latent.append(latEnc)\n",
    "\n",
    "        # latent via projection\n",
    "        Gstar = ex.adv_x.reshape(image_width*image_width)\n",
    "        [_,latL2] = generative_lib.Full_Projection(AEgen, Gstar, maxit, gamma, rand_init, sigma, x0, generative_lib.L2_Project)\n",
    "        AE_latent_L2.append(latL2)\n",
    "   \n",
    "    return [AE_latent,AE_latent_L2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_prod_lat(exs,VAE,VAEgen):\n",
    "    \n",
    "    # reconstruction by projection\n",
    "    maxit = 500\n",
    "    gamma  = 0.5\n",
    "    x0    = torch.zeros([num_latent])\n",
    "    rand_init = 1\n",
    "    sigma = 5\n",
    "    \n",
    "    VAE_latent_L2  = [];\n",
    "    VAE_latent     = [];\n",
    "    \n",
    "    for ex in exs:\n",
    "        Gstar = ex.x.reshape([1,image_width*image_width])\n",
    "        \n",
    "        # latent via encoder\n",
    "        [latEnc,z_mean,z_log_var] = VAE.encoder(Gstar)\n",
    "        VAE_latent.append(latEnc)\n",
    "    \n",
    "        # latent via projection\n",
    "        Gstar = ex.x.reshape(image_width*image_width) #model.decoder(test_enc).detach()\n",
    "        [_,latL2] = generative_lib.Full_Projection(VAEgen, Gstar, maxit, gamma, rand_init, sigma, x0, generative_lib.L2_Project)\n",
    "        VAE_latent_L2.append(latL2)\n",
    "   \n",
    "    return [VAE_latent,VAE_latent_L2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathAE = 'trained_models/AE_MNIST.pt'\n",
    "num_features = 784\n",
    "num_hidden_1 = 32\n",
    "\n",
    "AE = generative_lib.AE_1L(num_features,num_hidden_1)\n",
    "AE.load_state_dict(torch.load(pathAE))\n",
    "AE.eval()\n",
    "\n",
    "AEgen = generative_lib.AEcopyGen(AE,num_features,num_hidden_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-60fa681f7873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpkl_path\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0madversary_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'advex.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mAE_latent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE_latent_L2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprod_lat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAEgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-231-39e79b623f99>\u001b[0m in \u001b[0;36mprod_lat\u001b[0;34m(exs, AE, AEgen)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# latent via projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mGstar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatL2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerative_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFull_Projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAEgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerative_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL2_Project\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mAE_latent_L2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatL2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joriococola/Desktop/CS 6140/project 6140/GitHub/CS6140_LatentClassify/generative_lib.pyc\u001b[0m in \u001b[0;36mFull_Projection\u001b[0;34m(generator, Gstar, maxit, gamma, rand_init, sigma, x0, Project)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mxk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0ml2_loss_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_loss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0ml2_loss_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2_loss_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joriococola/Desktop/CS 6140/project 6140/GitHub/CS6140_LatentClassify/generative_lib.pyc\u001b[0m in \u001b[0;36mL2_Project\u001b[0;34m(generator, Gstar, maxit, x0, gamma)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mGxk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0ml2_loss_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGxk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mGstar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0ml2_loss_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/DL27/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joriococola/Desktop/CS 6140/project 6140/GitHub/CS6140_LatentClassify/generative_lib.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/DL27/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/DL27/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/DL27/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_50conf_advex/Logistic_LRL_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[AE_latent,AE_latent_L2] = prod_lat(exs,AE,AEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'AE_latent.pkl', \"w+\")\n",
    "pickle.dump(AE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'AE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(AE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a27c95c90>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random img in the test set\n",
    "idx = random.randint(0, len(exs))\n",
    "ex = exs[idx]\n",
    "adv_img = ex.adv_x\n",
    "plt.imshow(adv_img.detach().numpy().reshape([image_width,image_width]),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a27cf1450>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = AE_latent[idx]\n",
    "climg = AEgen(lat)\n",
    "plt.imshow(climg.detach().numpy().reshape([image_width,image_width]),cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_1L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[AE_latent,AE_latent_L2] = prod_lat(exs,AE,AEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'AE_latent.pkl', \"w+\")\n",
    "pickle.dump(AE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'AE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(AE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_2L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[AE_latent,AE_latent_L2] = prod_lat(exs,AE,AEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'AE_latent.pkl', \"w+\")\n",
    "pickle.dump(AE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'AE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(AE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathVAE = 'trained_models/VAE_MNIST.pt'\n",
    "\n",
    "num_features = 784\n",
    "num_hidden_1 = 150\n",
    "num_latent   = 32\n",
    "\n",
    "VAE = generative_lib.VAE(num_features,num_hidden_1,num_latent)\n",
    "VAE.load_state_dict(torch.load(pathVAE))\n",
    "VAE.eval()\n",
    "\n",
    "VAEgen = generative_lib.VAEcopyGen(VAE,num_features,num_hidden_1,num_latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_LRL_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[VAE_latent,VAE_latent_L2] = VAE_prod_lat(exs,VAE,VAEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'VAE_latent.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'VAE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_1L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[VAE_latent,VAE_latent_L2] = VAE_prod_lat(exs,VAE,VAEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'VAE_latent.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'VAE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_2L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[VAE_latent,VAE_latent_L2] = VAE_prod_lat(exs,VAE,VAEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'VAE_latent.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'VAE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL27]",
   "language": "python",
   "name": "conda-env-DL27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
