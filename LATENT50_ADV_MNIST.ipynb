{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.15 |Anaconda, Inc.| (default, Nov 13 2018, 17:07:45) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli\n",
    "from matplotlib import cm\n",
    "from numpy import linalg as LA\n",
    "from mpl_toolkits.mplot3d import Axes3D # This import has side effects required for the kwarg projection='3d' in the call to fig.add_subplot\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import generative_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generative_lib' from 'generative_lib.pyc'>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(generative_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers import AdversarialExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(adversary_path, delta = 500.0):\n",
    "    af = open(adversary_path, \"rb\")\n",
    "    exs = pickle.load(af)\n",
    "    af.close()\n",
    "\n",
    "    # remove all adversary that is None\n",
    "    #exs = filter(lambda ex: ex is not None, exs)\n",
    "    # remove all adversary whose norm is > delta\n",
    "    #exs = filter(lambda ex: ex.adv_diff_norm < delta, exs)\n",
    "    # sort examples by increasing diff norm\n",
    "    #exs.sort(key = lambda ex: ex.adv_diff_norm)\n",
    "    \n",
    "    return exs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_lat(exs,AE,AEgen):\n",
    "    \n",
    "    # reconstruction by projection\n",
    "    maxit = 500\n",
    "    gamma  = 0.5\n",
    "    x0    = torch.zeros([num_hidden_1])\n",
    "    rand_init = 1\n",
    "    sigma = 5\n",
    "    \n",
    "    AE_latent_L2  = [];\n",
    "    AE_latent     = [];\n",
    "    \n",
    "    for ex in exs:\n",
    "        Gstar = ex.adv_x.reshape(image_width*image_width)\n",
    "\n",
    "        # latent via encoder\n",
    "        latEnc = AE.encoder(Gstar)\n",
    "        AE_latent.append(latEnc)\n",
    "\n",
    "        # latent via projection\n",
    "        Gstar = ex.adv_x.reshape(image_width*image_width)\n",
    "        [_,latL2] = generative_lib.Full_Projection(AEgen, Gstar, maxit, gamma, rand_init, sigma, x0, generative_lib.L2_Project)\n",
    "        AE_latent_L2.append(latL2)\n",
    "   \n",
    "    return [AE_latent,AE_latent_L2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_prod_lat(exs,VAE,VAEgen):\n",
    "    \n",
    "    # reconstruction by projection\n",
    "    maxit = 500\n",
    "    gamma  = 0.5\n",
    "    x0    = torch.zeros([num_latent])\n",
    "    rand_init = 1\n",
    "    sigma = 5\n",
    "    \n",
    "    VAE_latent_L2  = [];\n",
    "    VAE_latent     = [];\n",
    "    \n",
    "    for ex in exs:\n",
    "        Gstar = ex.x.reshape([1,image_width*image_width])\n",
    "        \n",
    "        # latent via encoder\n",
    "        [latEnc,z_mean,z_log_var] = VAE.encoder(Gstar)\n",
    "        VAE_latent.append(latEnc)\n",
    "    \n",
    "        # latent via projection\n",
    "        Gstar = ex.x.reshape(image_width*image_width) #model.decoder(test_enc).detach()\n",
    "        [_,latL2] = generative_lib.Full_Projection(VAEgen, Gstar, maxit, gamma, rand_init, sigma, x0, generative_lib.L2_Project)\n",
    "        VAE_latent_L2.append(latL2)\n",
    "   \n",
    "    return [VAE_latent,VAE_latent_L2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathAE = 'trained_models/AE_MNIST.pt'\n",
    "num_features = 784\n",
    "num_hidden_1 = 32\n",
    "\n",
    "AE = generative_lib.AE_1L(num_features,num_hidden_1)\n",
    "AE.load_state_dict(torch.load(pathAE))\n",
    "AE.eval()\n",
    "\n",
    "AEgen = generative_lib.AEcopyGen(AE,num_features,num_hidden_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_50conf_advex/Logistic_LRL_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[AE_latent,AE_latent_L2] = prod_lat(exs,AE,AEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'AE_latent.pkl', \"w+\")\n",
    "pickle.dump(AE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'AE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(AE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_50conf_advex/Logistic_1L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[AE_latent,AE_latent_L2] = prod_lat(exs,AE,AEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'AE_latent.pkl', \"w+\")\n",
    "pickle.dump(AE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'AE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(AE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_50conf_advex/Logistic_2L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[AE_latent,AE_latent_L2] = prod_lat(exs,AE,AEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'AE_latent.pkl', \"w+\")\n",
    "pickle.dump(AE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'AE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(AE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathVAE = 'trained_models/VAE_MNIST.pt'\n",
    "\n",
    "num_features = 784\n",
    "num_hidden_1 = 150\n",
    "num_latent   = 32\n",
    "\n",
    "VAE = generative_lib.VAE(num_features,num_hidden_1,num_latent)\n",
    "VAE.load_state_dict(torch.load(pathVAE))\n",
    "VAE.eval()\n",
    "\n",
    "VAEgen = generative_lib.VAEcopyGen(VAE,num_features,num_hidden_1,num_latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_LRL_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[VAE_latent,VAE_latent_L2] = VAE_prod_lat(exs,VAE,VAEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'VAE_latent.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'VAE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_1L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[VAE_latent,VAE_latent_L2] = VAE_prod_lat(exs,VAE,VAEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'VAE_latent.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'VAE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary_path = 'adversary_dataset/CONFIDENCE_50/mnist_img_advex/Logistic_2L_advex/'\n",
    "pkl_path       = adversary_path + 'advex.pkl'\n",
    "exs = load_pkl(pkl_path)\n",
    "[VAE_latent,VAE_latent_L2] = VAE_prod_lat(exs,VAE,VAEgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save latents via Encoder\n",
    "pickle_f = open(adversary_path+'VAE_latent.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent, pickle_f)\n",
    "pickle_f.close()\n",
    "    \n",
    "# save latents via Projection\n",
    "pickle_f = open(adversary_path+'VAE_latent_L2.pkl', \"w+\")\n",
    "pickle.dump(VAE_latent_L2, pickle_f)\n",
    "pickle_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL27]",
   "language": "python",
   "name": "conda-env-DL27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
